{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos carpeta donde van a ir los CSV's\n",
    "from os import mkdir\n",
    "mkdir(r\"C:\\Users\\andrea\\Documents\\Kevin - Data Science\\Mi corte 04\\LABS\\PI01_DATA_ENGINEERING\\Carpeta_csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Abrimos el archivo CSV agregamos semana y lo guardamos en la carpeta\n",
    "ps1= pd.read_csv(r'C:\\Users\\andrea\\Documents\\Kevin - Data Science\\Mi corte 04\\LABS\\PI01_DATA_ENGINEERING\\Datasets relevamiento precios ORIGINAL\\precios_semana_20200413.csv', encoding=\"utf16\", dtype=str)\n",
    "ps1['Semana'] = '2020-04-13'\n",
    "ps1 = ps1.dropna()\n",
    "ps1.to_csv(r\"C:\\Users\\andrea\\Documents\\Kevin - Data Science\\Mi corte 04\\LABS\\PI01_DATA_ENGINEERING\\Carpeta_csv\\precios_semana_20200413.csv\",encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Abrimos el JSON, agregamos semanas y lo transformamos a csv, luego guardamos en carpeta\n",
    "ps2=pd.read_json(r'C:\\Users\\andrea\\Documents\\Kevin - Data Science\\Mi corte 04\\LABS\\PI01_DATA_ENGINEERING\\Datasets relevamiento precios ORIGINAL\\precios_semana_20200503.json')\n",
    "ps2['Semana'] = '2020-05-03'\n",
    "ps2['precio'] = ps2['precio'].replace({'':0}, regex=True)\n",
    "ps2.to_csv(r\"C:\\Users\\andrea\\Documents\\Kevin - Data Science\\Mi corte 04\\LABS\\PI01_DATA_ENGINEERING\\Carpeta_csv\\precios_semana_20200503.csv\",encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Abrimos TXT viene concatenado entonces separamos en 3 columnas y renombramos las columnas, luego exportamos a csv\n",
    "ps3= pd.read_fwf(r'C:\\Users\\andrea\\Documents\\Kevin - Data Science\\Mi corte 04\\LABS\\PI01_DATA_ENGINEERING\\Datasets relevamiento precios ORIGINAL\\precios_semana_20200518.txt')\n",
    "ps3= ps3['precio|producto_id|sucursal_id'].str.split('|',expand= True)\n",
    "ps3.rename(columns={0:'precio',1:'producto_id',2:'sucursal_id'},inplace=True)\n",
    "ps3['Semana'] = '2020-05-18'\n",
    "ps3['precio'] = ps3['precio'].replace({'':0}, regex=True)\n",
    "ps3.to_csv(r\"C:\\Users\\andrea\\Documents\\Kevin - Data Science\\Mi corte 04\\LABS\\PI01_DATA_ENGINEERING\\Carpeta_csv\\precios_semana_20200518.csv\",encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar paginas excel, uniendolas ya que tienen el mismo formato \n",
    "ps4=pd.read_excel(r\"C:\\Users\\andrea\\Documents\\Kevin - Data Science\\Mi corte 04\\LABS\\PI01_DATA_ENGINEERING\\Datasets relevamiento precios\\precios_semanas_20200419_20200426.xlsx\", dtype=str, sheet_name = None)\n",
    "ps4 = pd.concat (pd.read_excel(r\"C:\\Users\\andrea\\Documents\\Kevin - Data Science\\Mi corte 04\\LABS\\PI01_DATA_ENGINEERING\\Datasets relevamiento precios\\precios_semanas_20200419_20200426.xlsx\", dtype=str,engine='openpyxl', sheet_name = None), ignore_index = True )\n",
    "#reordenamos columnas\n",
    "ps4=ps4[['precio','producto_id','sucursal_id']]\n",
    "#quitando las que tienen los ceros \n",
    "ps4['sucursal_id'] = ps4['sucursal_id'].replace({'00:00:00':''}, regex=True)\n",
    "#agregamos semanas\n",
    "ps4['Semana'] = '2020-04-19'\n",
    "ps4['Semana'][478910:] = '2020-04-26'\n",
    "ps4 = ps4.dropna()\n",
    "#convertimos en CSV\n",
    "ps4.to_csv(r\"C:\\Users\\andrea\\Documents\\Kevin - Data Science\\Mi corte 04\\LABS\\PI01_DATA_ENGINEERING\\Carpeta_csv\\precios_semanas_20200419_20200426.csv\",encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos csv y hacemos limpieza\n",
    "ps5 = pd.read_csv(r'C:\\Users\\andrea\\Documents\\Kevin - Data Science\\Mi corte 04\\LABS\\PI01_DATA_ENGINEERING\\Datasets relevamiento precios ORIGINAL\\sucursal.csv',dtype=str)\n",
    "#separamos columna id\n",
    "ps5separado = ps5['id'].str.split('-',expand=True)\n",
    "ps5s = ps5separado.rename(columns={0:'comercio_id',1:'bandera_id',2:'sucursal_id'},inplace=True)\n",
    "#cambiamos nombre\n",
    "ps5.rename(columns={'banderaId':'bandera_id'},inplace=True)\n",
    "ps5 = pd.merge(ps5,ps5separado, on='bandera_id', how='outer')\n",
    "ps5 = ps5.drop(['id'], axis=1)\n",
    "#cambiamos unas columnas dejando primera mayuscula y reordenamos columnas\n",
    "ps5['localidad'] = ps5['localidad'].str.title()\n",
    "ps5 = ps5[['sucursal_id','comercio_id','bandera_id','banderaDescripcion','comercioRazonSocial','provincia','localidad', 'direccion','lat','lng', 'sucursalNombre','sucursalTipo']]\n",
    "#normalizamos varias casillas\n",
    "ps5['sucursalNombre'] = ps5['sucursalNombre'].replace({'SIBelgrano [Calle Belgrano 266/70]':'Belgrano-Calle Belgrano 266/70'}, regex=True)\n",
    "ps5['sucursalNombre'] = ps5['sucursalNombre'].replace({'.':''}, regex=True)\n",
    "ps5['localidad'] = ps5['localidad'].replace({',':''}, regex=True)\n",
    "ps5['direccion'] = ps5['direccion'].replace({',':''}, regex=True)\n",
    "ps5.to_csv(r\"C:\\Users\\andrea\\Documents\\Kevin - Data Science\\Mi corte 04\\LABS\\PI01_DATA_ENGINEERING\\Carpeta_csv\\sucursal.csv\",encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importamos Productos\n",
    "ps6 = pd.read_parquet(r\"C:\\Users\\andrea\\Documents\\Kevin - Data Science\\Mi corte 04\\LABS\\PI01_DATA_ENGINEERING\\Datasets relevamiento precios ORIGINAL\\producto.parquet\")\n",
    "#modificamos la columna nombre para mysql\n",
    "ps6['nombre'] = ps6['nombre'].replace({',':''}, regex=True)\n",
    "#borramos columnas vacias\n",
    "ps6 = ps6.drop(['categoria1','categoria2','categoria3'], axis=1)\n",
    "#Exportamos a CSV\n",
    "ps6.to_csv(r\"C:\\Users\\andrea\\Documents\\Kevin - Data Science\\Mi corte 04\\LABS\\PI01_DATA_ENGINEERING\\Carpeta_csv\\productos.csv\",encoding='utf-8', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2c1dbd8a15f6c848e314ffe25b11bf32d74119c3bb94b8ff09eced7db0a6ad4a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
